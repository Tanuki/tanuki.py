import json
from monkey_patch.models.function_description import FunctionDescription
from monkey_patch.validator import Validator
from monkey_patch.function_modeler import FunctionModeler
from monkey_patch.language_models.language_modeler import LanguageModel

def repair_output(args: tuple,
                    kwargs: dict,
                    function_description: FunctionDescription, 
                    choice, 
                    validator: Validator, 
                    function_modeler: FunctionModeler, 
                    language_modeler: LanguageModel) -> tuple:
        """
        Repair an output, that failed type validation by generating a new output using the teacher model and the error
        Args:
            args (tuple): The args of the function
            kwargs (dict): The kwargs of the function
            function_description (FunctionDescription): The function description
            choice: The output that failed type validation, type is arbitrary
            validator (Validator): The validator object
            function_modeler (FunctionModeler): The function modeler object
            language_modeler (LanguageModel): The language model object
        
        Returns:
            choice (str): The choice that was generated by the language model
            choice_parsed: The parsed choice, type is arbitrary
            valid (bool): Whether the output was correctly repaired was valid
        """
        
        # get the teacher models
        teacher_models = function_modeler.get_models(function_description.__hash__())[1]
        valid = False
        retry_index = 5
        f = str(function_description.__dict__.__repr__() + "\n")
        error = f"Output type was not valid. Expected an valid object of type {function_description.output_type_hint}, got '{choice}'"
        # instantiate the failed outputs list
        failed_outputs_list = [(choice, error)]
        while retry_index > 0 and not valid:
            # get the alignments
            aligns = function_modeler.get_alignments(function_description.__hash__(), max=5)
            examples = "\n".join([f"Inputs:\nArgs: {align['args']}\nKwargs {align['kwargs']}\nOutput: {align['output']}" for align in aligns])
            # Generate the reparied LLM output
            choice = language_modeler.repair_generate(args, kwargs, f, failed_outputs_list, examples, teacher_models)
            if not choice:
                # if no choice then the input was too long for the model
                # no specific error but the retry index goes down
                retry_index -= 1
                continue

            # start parsing the object
            try:
                # json load
                choice_parsed = json.loads(choice)
            except:
                # if it fails, it's not a json object, try eval
                try:
                    choice_parsed = eval(choice)
                except: 
                    choice_parsed = choice

            valid = validator.check_type(choice_parsed, function_description.output_type_hint)
            if not valid:
                # if it's not valid, add it to the failed outputs list
                error = f"Output type was not valid. Expected an object of type {function_description.output_type_hint}, got '{choice}'"
                failed_outputs_list.append((choice, error))
                retry_index -= 1

        return choice, choice_parsed, valid